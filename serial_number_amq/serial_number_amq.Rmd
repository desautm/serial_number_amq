---
title: Le problème du char d'assaut allemand

author: Marc-André Désautels
affiliation: département de mathématiques
establishment: Cégep de Saint-Jean-sur-Richelieu
email: \href{mailto:marc-andre.desautels@cstjean.qc.ca}{marc-andre.desautels@cstjean.qc.ca}
website: \href{https://www.cstjean.qc.ca/}{https://www.cstjean.qc.ca/}

abstract: |
  Durant la seconde guerre mondiale, les alliés avaient un besoin criant d’estimer avec précision la quantité de matériel militaire que l’Allemagne nazie produisait. Les estimations provenant des services de renseignements habituels étaient contradictoires et incertaines. Les gouvernements Britanniques et Américains se tournèrent donc vers des statisticiens pour savoir si leurs estimations pouvaient être améliorées. Nous présenterons une introduction aux notions mathématiques utilisées.
  
keywords: Statistiques, Estimation, Simulation

output: rticles::amq_article
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
set.seed(39894095)

library(mosaic)
library(purrr)
library(tidyr)
library(reshape2)
library(tidyverse)

# Définition des fonctions pour le calcul des mesures sur les numéros de série.

N1 <- function(ech){
  return(round(2*median(ech)-1))
}

N2 <- function(ech){
  return(round(2*mean(ech)-1))
}

N3 <- function(ech){
  if (length(ech) == 1) return(ech)
  else return(round(max(ech)+min(ech)-1))
}

N4 <- function(ech){
  if (length(ech) == 1) return(ech)
  else{
    l <- length(unique(ech))
  return(round((l+1)/l*max(ech)-1))
  }
}

N5 <- function(ech){
  if (length(ech) == 1) return(ech)
  else{
    l <- length(unique(ech))
    return(round((max(ech)-min(ech))*(l+1)/(l-1)-1))
  }
}
```


# Introduction \label{intro}

TODO [https://rstudio-pubs-static.s3.amazonaws.com/59464_ce1bbf886d0841cd8ecc46c1852b352e.html](https://rstudio-pubs-static.s3.amazonaws.com/59464_ce1bbf886d0841cd8ecc46c1852b352e.html)

Au début de l'année 1943, la *Economic Warfare Division* de l'ambassade américaine à Londres commença à analyser divers marquages obtenus à partir d'équipements allemands capturés ou détruits sur le front. Plus particulièrement, les numéros de séries ont été utilisés pour estimer la force de production de la machine de guerre allemande. L'article *An Empirical Approach to Economic Intelligence in World War II* \cite{Ruggles1947} explique en grand détail le développement des techniques utilisés pour faire cette estimation, les problèmes rencontrés et les solutions qui y ont remédiés. Nous invitons le lecteur intéressé par l'aspect pratico-pratique de ces techniques à lire cet article.

Le problème du char d'assaut allemand est nommé d'après son application par les alliés à l'estimation du nombre de chars d'assaut produits par l'Allemagne. Mais en fait, ce problème regroupe l'estimation du nombre de nombreux produits de guerre allemands, par exemple les camions, les fusils, les bombes et les fusées, voir \cite{Ruggles1947}. Les russes ont également utilisé des techniques similaires pour estimer la production de char d'assaut allemands \cite{Volz2008}. Durant les années 80, des militaires Américains ont eu accès aux lignes de production de chars d'assaut *Merkava* israéliens. Le nombre de chars produits était confidentiel, mais le colone Dupuy indique que puisque chaque chars possédait un numéro de série, il aurait pu estimer la production, voir \cite{Johnson}

Les formules développées dans cet article ont aussi été utilisées dans des contextes non-militaires. Par exemple, elles ont été utilisées pour estimer le nombre de *Commodore 64* produits, voir \cite{commodore64}. Le premier modèle de iPhone, commercialisé en 2007 aux États-Unis, a été vendu au nombre de 9 190 680, suite à des estimations faites à partir des codes IMEI (*The International Mobile Equipment Identity*) de nombreux utilisateurs, voir \cite{iphone}. 

Dans cet article, nous nous intéresserons à l'estimation du nombre d'items $N$ à partir d'un échantillon aléatoire dans le cas où les items sont numérotés de façon séquentielle.

# Les mathématiques \label{maths}

## Préalables

Supposons que nous avons une population d'objets numérotés de la façon suivante : $1$, $2$, $3$, ... , $N$, où $N$ est **inconnu**. En d'autres mots, les objets de notre population doivent être numérotés de façon *séquentielle*. Nous pigeons, __sans remise__, un échantillon $X_1$, $X_2$, $X_3$, ..., $X_n$, de taille $n$ à partir de la population. Nous voulons estimer la valeur de $N$ à partir de l'échantillon prélevé.

Pour calculer les diverses mesures statistiques dont nous aurons besoin, nous allons classer les unités statistiques de notre échantillon en ordre croissant. Nous avons:
$$X_{(1)} <  X_{(2)} < X_{(3)} < \ldots < X_{(n-1)} < X_{(n)}$$
où les valeurs $X_{(1)}$, $X_{(2)}$, $X_{(3)}$, ..., $X_{(n)}$ sont les valeurs ordonnées de l'échantillon $X_1$, $X_2$, $X_3$, ..., $X_n$. En particulier, $X_{(1)}$ est la plus petite valeur de l'échantillon et $X_{(n)}$ est la plus grande.

À partir de nos définitions précédentes, il est possible de calculer l'espérance de la valeur $X_{(A)}$ ($\esp (X_{(A)})$), la variance de la valeur $X_{(A)}$ ($\var(X_{(A)})$) et enfin la covariance des valeurs $X_{(A)}$ et $X_{(B)}$ ($\cov(X_{(A)},X_{(B)})$). Nous utiliserons ces mesures statistiques pour calculer l'espérance et la variance des estimateurs que nous construirons. Malheureusement, retrouver ces mesures statistiques nécessite des identités combinatoires et de fastidieux calculs. Pour ne pas alourdir le texte, nous donnerons ces mesures sans démonstration. Par contre, pour la lectrice ou le lecteur intéressé, vous pourrez trouver à l'annexe \ref{calculs_proba} une idée de la technique utilisée ainsi que la démonstration de $\esp(X_{(A)})$.

Nous utiliserons donc, sans démonstration, les trois mesures du tableau \ref{tab:mesures_stat}. La lectrice ou le lecteur curieux pourront aller aux annexes \ref{rappel_esperance} et \ref{calculs_proba} pour quelques rappels sur les notions d'espérance, de variance et de covariance ainsi que la démonstration de $E(X_{(A)})$. Les démonstrations de $\var(X_{(A)})$ et $\cov(X_{(A)},X_{(B)})$ se font d'une manière similaire.
\begin{table}[ht]
\begin{center}
\begin{tabular}{|r|c|}
\hline
Mesure & Formule \\
\hline
\hline
$\esp (X_{(A)})$ & $\frac{A(N+1)}{n+1}$ \\ \hline
$\var(X_{(A)})$ & $\frac{A(n+1-A)(N+1)(N-n)}{(n+1)^2(n+2)}$ \\ \hline
$\cov(X_{(A)},X_{(B)})$ & $\frac{A(n+1-B)(N+1)(N-n)}{(n+1)^2(n+2)}$ \\ \hline
\end{tabular}
\end{center}
\caption{\label{tab:mesures_stat} {Les mesures de l'espérance, de la variance et de la covariance pour une valeur $X_{(A)}$ de notre échantillon.} }
\end{table}
À l'aide des trois mesures du tableau \ref{tab:mesures_stat}, nous allons maintenant trouver quatre estimés de $N$ en utilisant simplement notre "gros bon sens". La structure des prochaines sections est calquée sur \cite{Johnson}. Nous utiliserons aussi les notions présentées en \cite{Goodman1952} et \cite{Goodman1954}.

## Les trois situations possibles

Supposons que nous avons une population d'objets numérotés de la façon suivante : $s+1$, $s+2$, $s+3$, ... , $s+N$. Trois situations distinctes peuvent se produire:

1. $s$ est **connu** et égal à $0$ et $N$ est **inconnu**.

1. $s$ est **connu** mais différent de $0$ et $N$ est **inconnu**.

1. $s$ est **inconnu** et $N$ est **inconnu**.

Nous étudierons, dans l'ordre, les trois situations précédentes.

## La situation où $s$ est **connu** et égal à $0$ et $N$ est **inconnu**

Puisque $s$ est connu et égal à $0$, nous nous trouvons dans la situation où notre liste est numérotée de la façon suivante : $1$, $2$, ..., $N$. Cette situation est en fait un cas particulier d'une loi uniforme discrète de la forme $\unif(1,N)$.

### Le milieu de la liste

Pour trouver nos deux premiers estimateurs, nous allons débuter en supposant que nous connaissons la valeur milieu $m$ de la liste $1$, $2$, ..., $N$. Nous nous retrouvons dans la situation ci-dessous:
$$\underbrace{1,2,3,\ldots,m-1}_{m-1 \text{ éléments}},m,\underbrace{m+1,\ldots,N-2,N-1,N}_{m-1 \text{ éléments}}$$
Il y aura donc $m-1$ valeurs en-dessous de $m$ et $m-1$ valeurs au-dessus de $m$. Donc, si nous incluons la valeur milieu $m$, nous avons $N=(m-1)+1+(m-1)=2m-1$. Puisque nous ne connaissons pas la valeur milieu $m$, il est raisonnable de le remplacer par une estimation, par exemple la médiane $\widetilde{X}$ ou la moyenne $\overline{X}$. Nous pouvons maintenant obtenir nos deux premiers estimateurs.

### La médiane

Nous noterons notre premier estimateur $\widehat{N_1}=2\widetilde{X}-1$, où $\widetilde{X}$ représente la médiane de notre échantillon. Rappelons que pour $k$ données discrètes, la médiane se calcule de deux façons différentes, dépendamment du fait que le nombre de données soit pair ou impair.
\begin{align}
\widetilde{X} &= 
\begin{cases}
\frac{1}{2}\lr{X_{\lr{\tfrac{k}{2}}}+X_{\lr{\tfrac{k}{2}+1}}} & \text{ si $k$ est pair} \\
X_{\lr{\tfrac{k+1}{2}}} & \text{ si $k$ est impair} \\
\end{cases}
\label{eq:mediane}
\end{align}
Nous voulons vérifier si l'estimateur $\widehat{N_1}$ est non-biaisé, c'est-à-dire si l'espérance de $\widehat{N_1}$ est égale à $N$ ($\esp (\widehat{N_1})=N$). Nous voulons également calculer la variance de $\widehat{N_1}$. Pour éviter d'alourdir le texte, nous avons mis un exemple de calcul d'espérance et de variance à l'annexe \ref{calculs_estimateurs}. Nous obtenons les résultats du tableau

\begin{table}[ht]
\begin{center}
\begin{tabular}{|c|c|c|c|}
\hline
$i$ & $\widehat{N_i}$ & $\esp\lr{\widehat{N_i}}$ & $\var\lr{\widehat{N_i}}$ \\
\hline
\hline
\multirow{2}{*}{1}  & \multirow{2}{*}{$2\widetilde{X}-1$} & \multirow{2}{*}{$N$} & 
$\frac{(N-n)(N+1)}{n+2}$ pour $n$ impair \\
& & & $\frac{(N-n)(N+1)}{n+2}$ pour $n$ pair \\
\hline
\end{tabular}
\end{center}
\caption{\label{tab:estimateur_n1} {Les mesures de l'espérance, de la variance et de la covariance pour une valeur $X_{(A)}$ de notre échantillon.} }
\end{table}


En utlisant les mesures du tableau \ref{tab:mesures_stat}, nous obtenons:
\begin{align*}
E\lr{\widehat{N_1}} &= E\lr{2\widetilde{X}-1} \\
&= 2E\lr{\widetilde{X}}-1 \quad \text{par propriétés des espérances}
\end{align*}
Pour continuer, nous devons distinguer le cas pair du cas impair et utiliser l'équation \ref{eq:mediane}.

#### Le cas pair

Dans le cas pair, nous avons:
\begin{align*}
E\lr{\widehat{N_1}} &= 2E\lr{\widetilde{X}}-1 \\
&= 2E\lr{\dfrac{X_{\left(\tfrac{n}{2}\right)}+X_{\left(\tfrac{n}{2}+1\right)}}{2}}-1 \\
&= E\lr{X_{\lr{\tfrac{n}{2}}}}+E\lr{X_{\lr{\tfrac{n}{2}+1}}}-1 \\
&= \dfrac{\lr{\tfrac{n}{2}}(N+1)}{n+1}+\dfrac{\lr{\tfrac{n}{2}+1}(N+1)}{n+1}-1 \\
&= \dfrac{\cancel{(n+1)}(N+1)}{\cancel{n+1}}-1 \\
&= N
\end{align*}

Nous avons donc bien que l'espérance de cet estimateur correspond à la valeur de $N$ que nous désirons trouver.

#### Le cas impair

Dans le cas impair, nous avons:
\begin{align*}
E\lr{\widehat{N_1}} &= 2E\lr{\widetilde{X}}-1 \\
&= 2E\lr{X_{\left(\tfrac{n+1}{2}\right)} }-1 \\
&= 2\dfrac{\lr{\tfrac{n+1}{2}}(N+1)}{n+1}-1 \\
&= \dfrac{\cancel{(n+1)}(N+1)}{\cancel{n+1}}-1 \\
&= N
\end{align*}

Nous avons donc bien que l'espérance de cet estimateur correspond à la valeur de $N$ que nous désirons trouver.

### La moyenne

Notre second estimateur est $\widehat{N_2}=2\overline{X}-1$, où $\overline{X}$ représente la moyenne de notre échantillon. Rappelons que pour $k$ données discrètes, la moyenne se calcule de la façon suivante:
\begin{align}
\overline{X} &= \dfrac{X_{(1)}+X_{(2)}+\ldots +X_{(k-1)}+X_{(k)}}{k}
\label{eq:moyenne}
\end{align}

En utlisant les mesures du tableau \ref{tab:mesures_stat} et l'équation \ref{eq:moyenne}, nous obtenons:
\begin{align*}
E\lr{\widehat{N_2}} &= 2E\lr{\overline{X}}-1 \\
&= 2E\lr{\dfrac{X_{(1)}+X_{(2)}+\ldots +X_{(n-1)}+X_{(n)}}{n}}-1 \\
&= 
\end{align*}

Malheureusement, nos deux estimés $E\lr{\widehat{N_1}}$ et $E\lr{\widehat{N_2}}$ présentent un problème. Les valeurs de ces deux estimateurs peuvent être plus petites que le plus grand entier dans notre échantillon, c'est-à-dire $X_{(n)}$. Il est bien sûr impossible que la valeur $N$ que nous cherchons soit plus petite que la plus grande valeur de notre échantillon.

Pour vous convaincre, étudions l'échantillon de taille $n=3$ suivant, tel que $X_1=2$, $X_2=10$ et $X_3=3$. Dans cette situation, la médiane de l'échantillon est 3 et la moyenne est 5. Nous obtenons donc:

$$\widehat{N_1}=2\widetilde{X}-1=5 \qquad \text{et} \qquad \widehat{N_2}=2\overline{X}-1=9 $$

Malheureusement, nous savons que $N$ est supérieur ou égal à 10, le maximum de notre échantillon. Ces deux estimateurs ne sont donc pas adéquats, nous devrons en trouver d'autres.

### Deux autres estimés

Nous voulons maintenant trouver d'autres estimés qui sont toujours supérieurs ou égaux au plus grand entier de notre échantillon. Par symétrie, nous pouvons supposer que le nombre de numéros de série non-observés au-dessus de $X_{(n)}$ soit le même que le nombre de numéros de série non-observés en-dessous de $X_{(1)}$. Nous avons donc:

\begin{align*}
N-X_{(n)} &= X_{(1)}-1 \\
\widehat{N_3} &= X_{(n)}+X_{(1)}-1
\end{align*}

Si nous continuons le raisonnement précédent, il apparaît raisonnable de poser le nombre de numéros de série non-observés au-dessus de $X_{(n)}$ comme étant la moyenne du:

- nombre de numéros de série non-observés en-dessous de $X_{(1)}$;

- nombre de numéros de série non-observés entre $X_{(1)}$ et $X_{(2)}$;

- nombre de numéros de série non-observés entre $X_{(2)}$ et $X_{(3)}$;

- ...

- nombre de numéros de série non-observés entre $X_{(n-1)}$ et $X_{(n)}$.

Nous avons donc que $N-X_{(n)}$ est égal à:

\begin{align*}
N-X_{(n)} &= \frac{1}{n}\left[ (X_{(1)}-1)+(X_{(2)}-X_{(1)}-1)+(X_{(3)}-X_{(2)}-1)+\ldots+(X_{(n)}-X_{(n-1)}-1) \right] \\
&= \frac{X_{(n)}}{n}-1 \\
\widehat{N_4} &= \left( \frac{n+1}{n}\right) X_{(n)}-1
\end{align*}

## La situation où $s$ est **connu** mais différent de $0$ et $N$ est **inconnu**

Supposons que nous avons une population d'objets numérotés de la façon suivante : $s+1$, $s+2$, $s+3$, ... , $s+N$, où $N$ est inconnu mais $s$ est **connu**. Cette situation est en fait un cas particulier d'une loi uniforme discrète de la forme $\unif(s+1,s+N)$.

Nous pouvons résoudre ce problème en utilisant les estimés précédents et en soustrayant la valeur $s$ aux numéros de série obtenus.

Par exemple, si nous avons une population où les numéros de séries débutent à 500 et nous obtenons l'échantillon suivant:

```{r, echo = FALSE}
ech = sample(500:1000, 5)
ech
```

Pour estimer la valeur de $N$, nous soustrayons $499$ à notre échantillon et nous utilisons notre estimé $\hat{N_4}$. Nous avons donc:

```{r}
ech-499
N4(ech-499)
```

--

La population est en fait de taille 500.

## La situation où $s$ est **inconnu** et $N$ est **inconnu**

Supposons que nous avons une population d'objets numérotés de la façon suivante : $s+1$, $s+2$, $s+3$, ... , $s+N$, où $N$ est inconnu mais $s$ est **inconnu**.

Nous allons étudier la différence $d$ entre le plus grand $(X_{(n)})$ et le plus petit $(X_{(1)})$ des numéros de série, que nous notons $d$.

\begin{align*}
X_{(n)}-X_{(1)} &= E(X_{(n)}-X_{(1)}) \\
&= \dfrac{n\cdot(N+1)}{n+1}-\dfrac{1\cdot(N+1)}{n+1} \\
&= \dfrac{(n-1)(N+1)}{n+1} \\
N+1 &= \dfrac{(X_{(n)}-X_{(1)})(n+1)}{n-1} \\
\widehat{N_5} &= \dfrac{(X_{(n)}-X_{(1)})(n+1)}{n-1}-1
\end{align*}

# Quelques simulations \label{simul}

Pour visualiser les différences entre les quatre estimateurs trouvés, nous allons effectuer des simulations avec le logiciel `R`. Pour nos simulations, nous utiliserons une population de taille $N=500$. Nous pouvons créer cette population dans `R` de la façon suivante:
```{r,label="creation-pop"}
pop <- c(1:500)
```
Pour modéliser le problème qui nous intéresse, nous voulons piger, **sans remise**, un échantillon de notre population. Pour cette première simulation, nous pigerons un échantillon de taille $n=5$.
```{r,label="ech-remise-5"}
ech <- sample(pop, 5, replace = FALSE)
ech
```
Le minimum de notre échantillon est `r min(ech)` et le maximum est `r max(ech)`. Nous pouvons calculer les quatres estimés associés à l'échantillon précédent:
```{r,label="calcul-estimes-1",collapse=TRUE}
N1(ech)
N2(ech)
N3(ech)
N4(ech)
```
Pour bien visualiser les différences entre nos quatre estimateurs, nous effectuerons trois simulations distinctes. La figure \ref{fig:ech-taille-5} représente une simulation de 5 000 échantillons de taille 5 à partir d'une population de taille 500.

```{r ech-taille-5, echo = FALSE, fig.cap="Représentation sous forme d'histogrammes de 5 000 échantillons de taille 5, pour les quatres estimateurs", out.width="90%", fig.align='center'}
N <- 500
n <- 5
iter <- 5000
pop <- c(1:N)

ech5 <- tibble(id = map(1:iter, ~sample(pop, n, replace = TRUE)))
ech5 <- ech5 %>%
  mutate(N1 = map_dbl(id, N1)) %>%
  mutate(N2 = map_dbl(id, N2)) %>%
  mutate(N3 = map_dbl(id, N3)) %>%
  mutate(N4 = map_dbl(id, N4)) %>%
  gather(estimateur, valeur, N1, N2, N3, N4)

ggplot(data = ech5, mapping = aes(x = valeur))+
  geom_histogram(bins = 50, fill = "lightblue", color = "darkblue")+
  facet_grid(estimateur ~ .)+
  geom_vline(xintercept=N,linetype=2,color="black")+
  labs(
    x = "Estimations",
    y = "Fréquence"
  )
```

La figure \ref{fig:ech-taille-25} représente une simulation de 5 000 échantillons de taille 25 à partir d'une population de taille 500.

```{r ech-taille-25, echo = FALSE, fig.cap="Représentation sous forme d'histogrammes de 5 000 échantillons de taille 25, pour les quatres estimateurs", out.width="90%", fig.align='center'}
N <- 500
n <- 25
iter <- 5000
pop <- c(1:N)

ech25 <- tibble(id = map(1:iter, ~sample(pop, n, replace = TRUE)))
ech25 <- ech25 %>%
  mutate(N1 = map_dbl(id, N1)) %>%
  mutate(N2 = map_dbl(id, N2)) %>%
  mutate(N3 = map_dbl(id, N3)) %>%
  mutate(N4 = map_dbl(id, N4)) %>%
  gather(estimateur, valeur, N1, N2, N3, N4)

ggplot(data = ech25, mapping = aes(x = valeur))+
  geom_histogram(bins = 50, fill = "lightblue", color = "darkblue")+
  facet_grid(estimateur ~ .)+
  geom_vline(xintercept=N,linetype=2,color="black")+
  labs(
    x = "Estimations",
    y = "Fréquence"
  )
```

La figure \ref{fig:ech-taille-50} représente une simulation de 5 000 échantillons de taille 50 à partir d'une population de taille 500.

```{r ech-taille-50, echo = FALSE, fig.cap="Représentation sous forme d'histogrammes de 5 000 échantillons de taille 50, pour les quatres estimateurs", out.width="90%", fig.align='center'}
N <- 500
n <- 50
iter <- 5000
pop <- c(1:N)

ech50 <- tibble(id = map(1:iter, ~sample(pop, n, replace = TRUE)))
ech50 <- ech50 %>%
  mutate(N1 = map_dbl(id, N1)) %>%
  mutate(N2 = map_dbl(id, N2)) %>%
  mutate(N3 = map_dbl(id, N3)) %>%
  mutate(N4 = map_dbl(id, N4)) %>%
  gather(estimateur, valeur, N1, N2, N3, N4)

ggplot(data = ech50, mapping = aes(x = valeur))+
  geom_histogram(bins = 50, fill = "lightblue", color = "darkblue")+
  facet_grid(estimateur ~ .)+
  geom_vline(xintercept=N,linetype=2,color="black")+
  labs(
    x = "Estimations",
    y = "Fréquence"
  )
```

Nous simulons des populations de tailles 10 à 1 000. Pour chacune d'entre elles, nous choisissons 50 échantillons de taille 5 et nous calculons les quatre estimations.

```{r ech-10-1000, echo = FALSE, fig.cap="Représentation de 50 échantillons de taille 5 pigés pour des populations de tailles 10 à 1 000, pour les quatre estimateurs", out.width="90%", fig.align='center'}
ech1000 <- tibble(
  pop = rep(seq(10, 1000, 5), 50),
  id = map(pop, ~sample(.x, 5, replace = FALSE))
  )
ech1000 <- ech1000 %>%
  mutate(N1 = map_dbl(id, N1)) %>%
  mutate(N2 = map_dbl(id, N2)) %>%
  mutate(N3 = map_dbl(id, N3)) %>%
  mutate(N4 = map_dbl(id, N4)) %>%
  gather(estimateur, valeur, N1, N2, N3, N4) %>%
  select(-id)

ggplot(data = ech1000, aes(x = pop, y = valeur, color = estimateur))+
  geom_jitter(alpha=0.5)+
  labs(
    x = "Nombre de chars produits",
    y = "Estimation"
  )+
  geom_abline(intercept = 0, slope=1, color = "red") +
  scale_colour_discrete(name="Estimateur")
```


\appendix

# Rappels \label{rappel_esperance}

\begin{definition}[Espérance d'une variable discrète prenant un nombre fini de valeurs]
Soit $X$ une variable aléatoire discrète avec un nombre fini de valeurs $x_1$, $x_2$, ..., $x_k$ auxquelles sont associées les probabilités $p_1$, $p_2$, ..., $p_k$. L'espérance de $X$, notée $\esp (X)$ est définie comme:
$$ \esp (X) = x_1p_1+x_2p_2+\ldots +x_kp_k = \sum_{i=1}^k x_i p_i $$
\end{definition}

Voici quelques propriétés élémentaires concernant l'espérance de variables aléatoires.

- Soit $k\in\mathbb{R}$, alors $\esp(k)=k$.

- Soit $X_i$ où $i\in\set{1,2,\ldots,n}$, $n$ variables aléatoires définies sur le même espace probabiliste et $a_i\in\mathbb{R}$, alors $\esp\lr{\sum_{i=1}^na_iX_i}=\sum_{i=1}^n a_i\esp(X_i)$.

\begin{definition}[Variance]
Soit $X$ une variable aléatoire discrète avec un nombre fini de valeurs $x_1$, $x_2$, ..., $x_k$ auxquelles sont associées les probabilités $p_1$, $p_2$, ..., $p_k$. La variance de $X$, notée $\var (X)$ est définie comme:
$$ \var (X) = \esp\crochet{\lr{X-\esp(X)}^2} $$
\end{definition}

\begin{definition}[Covariance]
Soit $X$ et $Y$ deux variables aléatoires définies sur le même espace probabiliste et ayant chacune une variance finie. La covariance de $X$ et $Y$, notée $\cov(X,Y)$ est définie comme:
$$ \cov(X,Y)=\esp\crochet{\lr{X-\esp(X)}\lr{Y-\esp(Y)}} $$
\end{definition}

Voici quelques propriétés élémentaires concernant la variance et la covariance de variables aléatoires.

- Le théorème de König-Huygens donne la formule de variance alternative suivante: $\var(X)=\esp(X^2)-\lr{\esp(X)}^2$.

- Soit $X$ une variable aléatoire et $a,b\in\mathbb{R}$, alors $\var(aX+b)=a^2\var(X)$.

- Soit $X_i$ où $i\in\set{1,2,\ldots,n}$, $n$ variables aléatoires définies sur le même espace probabiliste et $a_i\in\mathbb{R}$, alors $\var\lr{\sum_{i=1}^n a_iX_i}=\sum_{i=1}^n a_i^2\var(X_i)+2\sum_{1\leq i< j\leq n} a_ia_j\cov(X_i,X_j)$.

- Une généralisation du théorème de König-Huygens pour la variance implique: $\cov(X,Y)=\esp(XY)-\esp(X)\esp(Y)$.

- $\cov(X,X)=\var(X)$

- $\cov(X,Y)=\cov(Y,X)$

# Calcul de probabilités \label{calculs_proba}

Nous voulons calculer la probabilité reliée à l'événement $X_{(A)}=i$, c'est-à-dire l'événement où l'unité statistique $X_{(A)}=i$. Pour bien comprendre la situation, nous allons utiliser le schéma ci-dessous:
\begin{align*}
\underbrace{X_{(1)} <  X_{(2)} < \ldots < X_{(A-1)}}_{A-1 \text{ éléments}} 
< X_{(A)} 
< \underbrace{X_{(A+1)} < \ldots < X_{(n-1)} < X_{(n)}}_{n-A \text{ éléments}}
\end{align*}
Nous remarquons que $A\in\set{1,2,3,\ldots, n}$ et $i\in\set{A,A+1,A+2,\ldots,N-n+A}$. En effet, la valeur de $i$ ne peut pas être plus petite que $A$ car il y a toujours $A-1$ valeurs plus petites que $A$. De plus, $A$ ne peut pas être plus grande  que $N-n+A$ car il y a toujours $N-n+A-1$ valeurs plus grandes que $A$.

Pour calculer les probabilités, il faut se rappeler que nous devons choisir $A-1$ éléments parmi $i-1$, ce qui correspond à $\binom{i-1}{A-1}$. De plus, nous devons choisir $n-A$ éléments parmi $N-i$, ce qui correspond à $\binom{N-i}{n-A}$. Enfin, nous choisissons un échantillon de taille $n$ parmi une population de taille $N$, ce qui correspond à $\binom{N}{n}$. Nous avons donc:
\begin{align*}
P(X_{(A)}=i) &= \dfrac{\binom{i-1}{A-1}\binom{N-i}{n-A}}{\binom{N}{n}} \qquad \text{où } i=A,A+1,\ldots,N-n+A
\end{align*}
Puisque les probabilités précédentes doivent sommer à un, nous avons:
\begin{align}
\sum_{i=A}^{N-n+A} P(X_{(A)}=i) &= 1 \nonumber\\
\sum_{i=A}^{N-n+A} \dfrac{\binom{i-1}{A-1}\binom{N-i}{n-A}}{\binom{N}{n}} &= 1 \nonumber\\
\sum_{i=A}^{N-n+A} \binom{i-1}{A-1}\binom{N-i}{n-A} &= \binom{N}{n} \label{eq:sumxA}
\end{align}

À l'aide de l'équation (\ref{eq:sumxA}), nous pouvons démontrer les résultats du tableau \ref{tab:mesures_stat}. Pour montrer au lecteur la façon de faire, nous présenterons la façon de démontrer l'espérance de $X_{(A)}$. Nous avons:
\begin{align}
E(X_{(A)}) &= \sum_{i=A}^{N-n+A} iP(X_{(A)}=i) \nonumber\\
&= \sum_{i=A}^{N-n+A} i\dfrac{\binom{i-1}{A-1}\binom{N-i}{n-A}}{\binom{N}{n}} \nonumber\\
&= \dfrac{1}{\binom{N}{n}}\sum_{i=A}^{N-n+A} i\binom{i-1}{A-1}\binom{N-i}{n-A} \nonumber\\
&= \dfrac{1}{\binom{N}{n}}\sum_{i=A}^{N-n+A} A\binom{i}{A}\binom{N-i}{n-A} 
\comeq{car $\binom{n}{k}=\dfrac{n}{k}\binom{n-1}{k-1}$} \nonumber\\
&= \dfrac{A}{\binom{N}{n}}\sum_{i=A}^{N-n+A} \binom{i}{A}\binom{N-i}{n-A} \nonumber\\
&= \dfrac{A}{\binom{N}{n}}\binom{N+1}{n+1} \comeq{par l'équation \ref{eq:sumxA} et changement d'indice} \nonumber\\
&= \dfrac{A(N+1)}{n+1} \label{eq:esperancexA}
\end{align}

Les démonstrations de $\var(X_{(A)})$ et $\cov(X_{(A)},X_{(B)})$ se font d'une manière similaire.

# Calculs d'espérance et de variance d'estimateurs \label{calculs_estimateurs}

Nous démontrons ici le calcul de l'espérance et de la variance de l'estimateur $\widehat{N_1}$, pour donner une idée à la lectrice ou au lecteur des idées à utiliser lors de la démonstration des espérances et des variances des autres estimateurs. Nous étudierons le cas où $n$ est pair.

## Calcul de l'espérance

Puisque $n$ est pair, la médiane est donnée par $\frac{1}{2}\lr{X_{\lr{n/2}}+X_{\lr{n/2+1}}}$ Ainsi:
\begin{align*}
\esp(\widehat{N_1}) &= \esp(2\widetilde{X}-1) \\
&= 2\esp(\widetilde{X})-1 \\
&= 2\esp\lr{\frac{1}{2}\lr{X_{\lr{n/2}}+X_{\lr{n/2+1}}}}-1 \\
&= \esp\lr{X_{\lr{n/2}}}+\esp\lr{X_{\lr{n/2+1}}}-1 \\
&= \frac{(\rfrac{n}{2})(N+1)}{n+1}+ \frac{(\rfrac{n}{2}+1)(N+1)}{n+1}-1 \\
&= \frac{(n+1)(N+1)}{n+1}-1 \\
&= N
\end{align*}

## Calcul de la variance

Puisque $n$ est pair, la médiane est donnée par $\frac{1}{2}\lr{X_{\lr{n/2}}+X_{\lr{n/2+1}}}$ Ainsi:
\begin{align*}
\var(\widehat{N_1}) &= \var(2\widetilde{X}-1) \\
&= 4\var(\widetilde{X}) \\
&= 4\var\lr{\frac{1}{2}\lr{X_{\lr{n/2}}+X_{\lr{n/2+1}}}} \\
&= \var\lr{X_{\lr{n/2}}+X_{\lr{n/2+1}}} \\
&= \var\lr{X_{\lr{n/2}}}+\var\lr{X_{\lr{n/2+1}}}+2\cov\lr{X_{\lr{n/2}},X_{\lr{n/2+1}}} \\
&= \frac{(n/2)(n+1-n/2)(N+1)(N-n)}{(n+1)^2(n+2)}+\frac{(n/2+1)(n+1-(n/2+1))(N+1)(N-n)}{(n+1)^2(n+2)}+ \\
&\qquad\qquad\qquad \ldots+2\frac{(n/2)(n+1-(n/2+1))(N+1)(N-n)}{(n+1)^2(n+2)} \\
&= (n^2+n)\frac{(N+1)(N-n)}{(n+1)^2(n+2)} \\
&= \frac{n}{n+1}\frac{(N+1)(N-n)}{(n+1)(n+2)}
\end{align*}
